{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Para entrenamiento\n",
    "path_to_json = './'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para Test\n",
    "path_to_json = 'C://Users//daoban//OneDrive//Tesis_QEC//SimulacionCircuitos//gen_sampler//p0_1'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = json_files[:len(json_files)-1] #xq ya hay una json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['X_corrections', 'X_stab_outcomes', 'Z_corrections', 'Z_stab_outcomes', 'error_added', 'failings', 'failings_total_NN', 'final_errors', 'n_correctable', 'n_fail', 'n_fail_NN', 'n_supra_gates', 'n_total', 'p_1q', 'p_2q', 'p_correctable', 'p_fail', 'p_fail_NN', 'p_meas', 'p_supra_gates'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_text.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_correc = []\n",
    "x_stab = []\n",
    "z_correc = []\n",
    "z_stab = []\n",
    "final_errors = []\n",
    "for index, js in enumerate(json_files):\n",
    "    with open(os.path.join(path_to_json, js)) as json_file:\n",
    "        json_text = json.load(json_file)\n",
    "        x_correc.append(json_text['X_corrections'])\n",
    "        x_stab.append(json_text['X_stab_outcomes'])\n",
    "        z_correc.append(json_text['Z_corrections'])\n",
    "        z_stab.append(json_text['Z_stab_outcomes'])\n",
    "        final_errors.append(json_text['failings_total_NN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relleno los que tienen solo dos mediciones iguales x\n",
    "for i in range(0,len(x_stab)):\n",
    "    for j in range(0,len(x_stab[i])):\n",
    "        if len(x_stab[i][j]) != 3:\n",
    "           x_stab[i][j].append(x_stab[i][j][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relleno los que tienen solo dos mediciones iguales z\n",
    "for i in range(0,len(z_stab)):\n",
    "    for j in range(0,len(z_stab[i])):\n",
    "        if len(z_stab[i][j]) != 3:\n",
    "           z_stab[i][j].append(z_stab[i][j][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataz_stab =[]\n",
    "for i in range(0,len(z_stab)):\n",
    "    for j in range(0,len(z_stab[i])):\n",
    "        for k in range(0,len(z_stab[i][j])):\n",
    "            for l in range(0,len(z_stab[i][j][k])):\n",
    "                dataz_stab.append(z_stab[i][j][k][l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "datax_stab =[]\n",
    "for i in range(0,len(x_stab)):\n",
    "    for j in range(0,len(x_stab[i])):\n",
    "        for k in range(0,len(x_stab[i][j])):\n",
    "            for l in range(0,len(x_stab[i][j][k])):\n",
    "                datax_stab.append(x_stab[i][j][k][l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = []\n",
    "for i in range(0,len(final_errors)):\n",
    "    for j in range(0,len(final_errors[i])):\n",
    "        numeric.append(final_errors[i][j])\n",
    "numeric = np.array(numeric).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "datax_stab = np.array(datax_stab).reshape((len(json_files)*len(json_text['X_corrections']),12))\n",
    "dataz_stab = np.array(dataz_stab).reshape((len(json_files)*len(json_text['X_corrections']),12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "indices = []\n",
    "for index, (vectx, vectz) in enumerate(zip(datax_stab,dataz_stab)):\n",
    "        if max(vectx)==0 & max(vectz)==0:\n",
    "            indices.append(index)\n",
    "delete = indices#[:corte]\n",
    "datax_stab=np.delete(datax_stab,delete,axis=0)\n",
    "dataz_stab=np.delete(dataz_stab,delete,axis=0)\n",
    "numeric = np.delete(numeric,delete,axis=0)\n",
    "datax3 = np.array(datax_stab).reshape(len(datax_stab)*3,4)\n",
    "dataz3 = np.array(dataz_stab).reshape(len(datax_stab)*3,4)\n",
    "numeric3 = []\n",
    "for i in range(0,len(datax_stab)):\n",
    "    for j in range(0,3):\n",
    "        numeric3.append(numeric[i])\n",
    "numeric3 = np.array(numeric3)\n",
    "data3_stab = np.concatenate((datax3,dataz3),axis = 1)\n",
    "data3 = np.concatenate((data3_stab,numeric3.reshape(len(datax_stab)*3,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for index, (vectx, vectz) in enumerate(zip(datax_stab,dataz_stab)):\n",
    "        if max(vectx)==0 & max(vectz)==0:\n",
    "            indices.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete = indices#[:corte]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "corte =len(datax_stab)-len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "datax_stab=np.delete(datax_stab,delete,axis=0)\n",
    "dataz_stab=np.delete(dataz_stab,delete,axis=0)\n",
    "numeric = np.delete(numeric,delete,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "datax3 = np.array(datax_stab).reshape(len(datax_stab)*3,4)\n",
    "dataz3 = np.array(dataz_stab).reshape(len(datax_stab)*3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric3 = []\n",
    "for i in range(0,len(datax_stab)):\n",
    "    for j in range(0,3):\n",
    "        numeric3.append(numeric[i])\n",
    "numeric3 = np.array(numeric3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3_stab = np.concatenate((datax3,dataz3),axis = 1)\n",
    "data3 = np.concatenate((data3_stab,numeric3.reshape(len(datax_stab)*3,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('training_p01.csv',data3,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_secuencia(secuencia,pasos_tiempo):\n",
    "    x, y = list(), list()\n",
    "    for i in range(len(secuencia)):\n",
    "        final_ix = i +pasos_tiempo\n",
    "        if final_ix > len(secuencia)-1:\n",
    "            break\n",
    "        #juntamos la serie y resultado del siguiente paso\n",
    "        seq_x, seq_y = secuencia[i:final_ix,:-1], secuencia[final_ix-1,-1]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasos_tiempo3 = 3\n",
    "x3_0, y3_0 = separar_secuencia(data3,pasos_tiempo3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = []\n",
    "y3 = []\n",
    "for index in range(0,len(x3_0)):\n",
    "    if index==0:\n",
    "        x3.append(x3_0[index])\n",
    "    elif index%3 == 0:\n",
    "        x3.append(x3_0[index])\n",
    "for index in range(0,len(y3_0)):\n",
    "    if index==0:\n",
    "        y3.append(y3_0[index])\n",
    "    elif index%3 == 0:\n",
    "        y3.append(y3_0[index])\n",
    "x3 = np.array(x3)\n",
    "y3 = np.array(y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(x3.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = x3[indices]\n",
    "y3 = y3[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train3 = x3[0:round(len(x3)*0.8)]\n",
    "y_train3 = y3[0:round(len(y3)*0.8)]\n",
    "x_test3 = x3[round(len(x3)*0.8):len(x3)]\n",
    "y_test3 = y3[round(len(y3)*0.8):len(y3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train3= keras.utils.to_categorical(y_train3,num_classes=2)\n",
    "y_test3 = keras.utils.to_categorical(y_test3,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stab3 = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(LSTM(128,\n",
    "               activation = 'relu',\n",
    "               return_sequences = True,\n",
    "               input_shape = (pasos_tiempo3,n_stab3)))\n",
    "model3.add(LSTM(64, activation='relu'))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(64,activation = 'relu'))\n",
    "model3.add(Dropout(0.3))\n",
    "model3.add(Dense(32,activation = 'relu'))\n",
    "model3.add(Dropout(0.3))\n",
    "model3.add(Dense(16,activation = 'relu'))\n",
    "model3.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "GPU sync failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\dov10\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dov10\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dov10\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: GPU sync failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-5975fe7021c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\dov10\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\dov10\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dov10\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2696\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2697\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_make_callable_from_options'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2698\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2699\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dov10\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    197\u001b[0m                 \u001b[1;31m# not already marked as initialized.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 is_initialized = session.run(\n\u001b[1;32m--> 199\u001b[1;33m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dov10\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dov10\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dov10\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dov10\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: GPU sync failed"
     ]
    }
   ],
   "source": [
    "model3.fit(x_train3, y_train3,batch_size=300, epochs=20,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save('modelo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324000/324000 [==============================] - 9s 29us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5007690983171816, 0.7523765431981028]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score3 = model3.evaluate(x_test3, y_test3, batch_size=256)\n",
    "score3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\daoban\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\daoban\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\daoban\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model3 = load_model('modelo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"\"\"x_correc_02e = []\n",
    "x_stab_02e = []\n",
    "z_correc_02e = []\n",
    "z_stab_02e = []\n",
    "final_errors_02e = []\n",
    "with open(path_to_json+'0_2.json') as json_file:\n",
    "    json_text = json.load(json_file)\n",
    "x_correc_02e.append(json_text['X_corrections'])\n",
    "x_stab_02e.append(json_text['X_stab_outcomes'])\n",
    "z_correc_02e.append(json_text['Z_corrections'])\n",
    "z_stab_02e.append(json_text['Z_stab_outcomes'])\n",
    "final_errors_02e.append(json_text['failings_total_NN'])\n",
    "for i in range(0,len(x_stab_02e)):\n",
    "    for j in range(0,len(x_stab_02e[i])):\n",
    "        if len(x_stab_02e[i][j]) != 3:\n",
    "           x_stab_02e[i][j].append(x_stab_02e[i][j][0])\n",
    "#relleno los que tienen solo dos mediciones iguales z\n",
    "for i in range(0,len(z_stab_02e)):\n",
    "    for j in range(0,len(z_stab_02e[i])):\n",
    "        if len(z_stab_02e[i][j]) != 3:\n",
    "           z_stab_02e[i][j].append(z_stab_02e[i][j][0])\n",
    "dataz_stab_02e =[]\n",
    "for i in range(0,len(z_stab_02e)):\n",
    "    for j in range(0,len(z_stab_02e[i])):\n",
    "        for k in range(0,len(z_stab_02e[i][j])):\n",
    "            for l in range(0,len(z_stab_02e[i][j][k])):\n",
    "                dataz_stab_02e.append(z_stab_02e[i][j][k][l])\n",
    "datax_stab_02e =[]\n",
    "for i in range(0,len(x_stab_02e)):\n",
    "    for j in range(0,len(x_stab_02e[i])):\n",
    "        for k in range(0,len(x_stab_02e[i][j])):\n",
    "            for l in range(0,len(x_stab_02e[i][j][k])):\n",
    "                datax_stab_02e.append(x_stab_02e[i][j][k][l])\n",
    "datax_stab_02e = np.array(datax_stab_02e).reshape((30000,12))\n",
    "dataz_stab_02e = np.array(dataz_stab_02e).reshape((30000,12))\n",
    "numeric_02e = []\n",
    "for i in range(0,len(final_errors_02e[0])):\n",
    "    for j in range(0,3):\n",
    "        numeric_02e.append(final_errors_02e[0][i])\n",
    "numeric_02e = np.array(numeric_02e).astype(int)\n",
    "indices = []\n",
    "for index, (vectx, vectz) in enumerate(zip(datax_stab_02e,dataz_stab_02e)):\n",
    "        if max(vectx)==0 & max(vectz)==0:\n",
    "            indices.append(index)\n",
    "delete_02e = indices#[:corte]\n",
    "datax_stab_02e=np.delete(datax_stab_02e,delete_02e,axis=0)\n",
    "dataz_stab_02e=np.delete(dataz_stab_02e,delete_02e,axis=0)\n",
    "numeric_02e = np.delete(numeric_02e,delete_02e,axis=0)\n",
    "datax3 = np.array(datax_stab_02e).reshape(len(datax_stab_02e)*3,4)\n",
    "dataz3 = np.array(dataz_stab_02e).reshape(len(datax_stab_02e)*3,4)\n",
    "numeric3 = []\n",
    "for i in range(0,len(datax_stab_02e)):\n",
    "    for j in range(0,3):\n",
    "        numeric3.append(numeric_02e[i])\n",
    "numeric3 = np.array(numeric3)\n",
    "data3_stab = np.concatenate((datax3,dataz3),axis = 1)\n",
    "data3 = np.concatenate((data3_stab,numeric3.reshape(len(datax_stab_02e)*3,1)),axis=1)\n",
    "pasos_tiempo3 = 3\n",
    "x3_0, y3_0 = separar_secuencia(data3,pasos_tiempo3)\n",
    "x3 = []\n",
    "y3 = []\n",
    "for index in range(0,len(x3_0)):\n",
    "    if index==0:\n",
    "        x3.append(x3_0[index])\n",
    "    elif index%3 == 0:\n",
    "        x3.append(x3_0[index])\n",
    "for index in range(0,len(y3_0)):\n",
    "    if index==0:\n",
    "        y3.append(y3_0[index])\n",
    "    elif index%3 == 0:\n",
    "        y3.append(y3_0[index])\n",
    "x3 = np.array(x3)\n",
    "x3=x3[round(len(x3)*0.8):len(x3)]\n",
    "y3 = np.array(y3)\n",
    "y3=y3[round(len(y3)*0.8):len(y3)]\n",
    "y3= keras.utils.to_categorical(y3,num_classes=2)\n",
    "acc_02e = model3.evaluate(x3, y3, batch_size=256)[1]\n",
    "delete_02e = len(delete_02e)\n",
    "acc_02e\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for file in json_files:\n",
    "    files.append(file.replace('.json',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = []\n",
    "for n in files:\n",
    "    numbers.append(n.replace('_',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_1 01\n",
      "2055/2055 [==============================] - 1s 304us/step\n",
      "0_2 02\n",
      "3317/3317 [==============================] - 0s 28us/step\n",
      "0_3 03\n",
      "4144/4144 [==============================] - 0s 26us/step\n",
      "0_4 04\n",
      "4674/4674 [==============================] - 0s 27us/step\n",
      "0_5 05\n",
      "5065/5065 [==============================] - 0s 28us/step\n",
      "0_6 06\n",
      "5296/5296 [==============================] - 0s 24us/step\n",
      "0_7 07\n",
      "5482/5482 [==============================] - 0s 26us/step\n",
      "0_8 08\n",
      "5579/5579 [==============================] - 0s 31us/step\n",
      "0_9 09\n",
      "5681/5681 [==============================] - 0s 27us/step\n",
      "1_0 10\n",
      "2003/2003 [==============================] - 0s 31us/step\n",
      "1_1 11\n",
      "3319/3319 [==============================] - 0s 33us/step\n",
      "1_2 12\n",
      "4171/4171 [==============================] - 0s 26us/step\n",
      "1_3 13\n",
      "4720/4720 [==============================] - 0s 26us/step\n",
      "1_4 14\n",
      "5081/5081 [==============================] - 0s 28us/step\n",
      "1_5 15\n",
      "5317/5317 [==============================] - 0s 26us/step\n",
      "1_6 16\n",
      "5476/5476 [==============================] - 0s 29us/step\n",
      "1_7 17\n",
      "5621/5621 [==============================] - 0s 33us/step\n",
      "1_8 18\n",
      "5687/5687 [==============================] - 0s 36us/step\n",
      "2_0 20\n",
      "3392/3392 [==============================] - 0s 28us/step\n",
      "2_1 21\n",
      "4203/4203 [==============================] - 0s 26us/step\n",
      "2_2 22\n",
      "4745/4745 [==============================] - 0s 26us/step\n",
      "2_3 23\n",
      "5111/5111 [==============================] - 0s 28us/step\n",
      "2_4 24\n",
      "5340/5340 [==============================] - 0s 26us/step\n",
      "2_5 25\n",
      "5515/5515 [==============================] - 0s 28us/step\n",
      "2_6 26\n",
      "5627/5627 [==============================] - 0s 28us/step\n",
      "2_7 27\n",
      "5701/5701 [==============================] - 0s 30us/step\n",
      "3_0 30\n",
      "4283/4283 [==============================] - 0s 26us/step\n",
      "3_1 31\n",
      "4786/4786 [==============================] - 0s 26us/step\n",
      "3_2 32\n",
      "5140/5140 [==============================] - 0s 24us/step\n",
      "3_3 33\n",
      "5378/5378 [==============================] - 0s 29us/step\n",
      "3_4 34\n",
      "5523/5523 [==============================] - 0s 31us/step\n",
      "3_5 35\n",
      "5635/5635 [==============================] - 0s 36us/step\n",
      "3_6 36\n",
      "5717/5717 [==============================] - 0s 60us/step\n",
      "4_0 40\n",
      "4847/4847 [==============================] - 0s 26us/step\n",
      "4_1 41\n",
      "5158/5158 [==============================] - 0s 27us/step\n",
      "4_2 42\n",
      "5388/5388 [==============================] - 0s 38us/step\n",
      "4_3 43\n",
      "5532/5532 [==============================] - 0s 25us/step\n",
      "4_4 44\n",
      "5659/5659 [==============================] - 0s 30us/step\n",
      "4_5 45\n",
      "5722/5722 [==============================] - 0s 27us/step\n",
      "5_0 50\n",
      "5217/5217 [==============================] - 0s 27us/step\n",
      "5_1 51\n",
      "5412/5412 [==============================] - 0s 26us/step\n",
      "5_2 52\n",
      "5582/5582 [==============================] - 0s 28us/step\n",
      "5_3 53\n",
      "5675/5675 [==============================] - 0s 66us/step\n",
      "5_4 54\n",
      "5741/5741 [==============================] - 0s 27us/step\n",
      "6_0 60\n",
      "5460/5460 [==============================] - 0s 29us/step\n",
      "6_1 61\n",
      "5596/5596 [==============================] - 0s 25us/step\n",
      "6_2 62\n",
      "5682/5682 [==============================] - 0s 25us/step\n",
      "6_3 63\n",
      "5763/5763 [==============================] - 0s 27us/step\n",
      "7_0 70\n",
      "5618/5618 [==============================] - 0s 25us/step\n",
      "7_1 71\n",
      "5716/5716 [==============================] - 0s 25us/step\n",
      "7_2 72\n",
      "5776/5776 [==============================] - 0s 27us/step\n",
      "8_0 80\n",
      "5736/5736 [==============================] - 0s 27us/step\n",
      "8_1 81\n",
      "5774/5774 [==============================] - 0s 27us/step\n",
      "9_0 90\n",
      "5799/5799 [==============================] - 0s 27us/step\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(files,numbers):\n",
    "    print(i,j)\n",
    "    t1 = texto.replace('0_2',i)\n",
    "    string = j+'e'\n",
    "    t2 = t1.replace('02e',string)\n",
    "    exec(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.array([acc_01e,acc_02e,acc_03e,acc_04e,acc_05e,acc_06e,acc_07e,acc_08e,acc_09e,acc_10e,acc_11e,acc_12e,acc_13e,acc_14e,acc_15e,acc_16e,acc_17e,acc_18e,acc_20e,acc_21e,acc_22e,acc_23e,acc_24e,acc_25e,acc_26e,acc_27e,acc_30e,acc_31e,acc_32e,acc_33e,acc_34e,acc_35e,acc_36e,acc_40e,acc_41e,acc_42e,acc_43e,acc_44e,acc_45e,acc_50e,acc_51e,acc_52e,acc_53e,acc_54e,acc_60e,acc_61e,acc_62e,acc_63e,acc_70e,acc_71e,acc_72e,acc_80e,acc_81e,acc_90e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete = np.array([delete_01e,delete_02e,delete_03e,delete_04e,delete_05e,delete_06e,delete_07e,delete_08e,delete_09e,delete_10e,delete_11e,delete_12e,delete_13e,delete_14e,delete_15e,delete_16e,delete_17e,delete_18e,delete_20e,delete_21e,delete_22e,delete_23e,delete_24e,delete_25e,delete_26e,delete_27e,delete_30e,delete_31e,delete_32e,delete_33e,delete_34e,delete_35e,delete_36e,delete_40e,delete_41e,delete_42e,delete_43e,delete_44e,delete_45e,delete_50e,delete_51e,delete_52e,delete_53e,delete_54e,delete_60e,delete_61e,delete_62e,delete_63e,delete_70e,delete_71e,delete_72e,delete_80e,delete_81e,delete_90e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19724, 13413,  9280,  6630,  4676,  3518,  2587,  2102,  1594,\n",
       "       19986, 13406,  9146,  6401,  4596,  3416,  2620,  1896,  1565,\n",
       "       13038,  8982,  6275,  4443,  3298,  2422,  1862,  1492,  8584,\n",
       "        6070,  4298,  3110,  2385,  1822,  1414,  5762,  4210,  3061,\n",
       "        2337,  1703,  1389,  3913,  2940,  2089,  1622,  1293,  2699,\n",
       "        2020,  1590,  1184,  1908,  1421,  1120,  1319,  1127,  1006])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for x in p:\\n    strings.append(str(x))\\nstrings = np.array(strings)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = ['acc_01e','acc_02e','acc_03e','acc_04e','acc_05e','acc_06e','acc_07e','acc_08e','acc_09e','acc_10e','acc_11e','acc_12e','acc_13e','acc_14e','acc_15e','acc_16e','acc_17e','acc_18e','acc_20e','acc_21e','acc_22e','acc_23e','acc_24e','acc_25e','acc_26e','acc_27e','acc_30e','acc_31e','acc_32e','acc_33e','acc_34e','acc_35e','acc_36e','acc_40e','acc_41e','acc_42e','acc_43e','acc_44e','acc_45e','acc_50e','acc_51e','acc_52e','acc_53e','acc_54e','acc_60e','acc_61e','acc_62e','acc_63e','acc_70e','acc_71e','acc_72e','acc_80e','acc_81e','acc_90e']\n",
    "#strings = []\n",
    "\"\"\"for x in p:\n",
    "    strings.append(str(x))\n",
    "strings = np.array(strings)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "peso_cero = ['delete_01e','delete_02e','delete_03e','delete_04e','delete_05e','delete_06e','delete_07e','delete_08e','delete_09e','delete_10e','delete_11e','delete_12e','delete_13e','delete_14e','delete_15e','delete_16e','delete_17e','delete_18e','delete_20e','delete_21e','delete_22e','delete_23e','delete_24e','delete_25e','delete_26e','delete_27e','delete_30e','delete_31e','delete_32e','delete_33e','delete_34e','delete_35e','delete_36e','delete_40e','delete_41e','delete_42e','delete_43e','delete_44e','delete_45e','delete_50e','delete_51e','delete_52e','delete_53e','delete_54e','delete_60e','delete_61e','delete_62e','delete_63e','delete_70e','delete_71e','delete_72e','delete_80e','delete_81e','delete_90e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail = 1-acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = 'summary_nn_p01.json'\n",
    "output_dict = {}\n",
    "for i in range(len(acc)):\n",
    "    output_dict[str((int(numbers[i][0]),int(numbers[i][1])))] = fail[i]\n",
    "output_json_file = open(output_filename, 'w')\n",
    "json.dump(output_dict, output_json_file)\n",
    "output_json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_cero = []\n",
    "for name, number in zip(peso_cero,delete):\n",
    "    p_cero.append([name,number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "for name, number in zip(p,fail):\n",
    "    final.append([name,number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results_30mil.txt\", 'w') as output:\n",
    "    for row in final:\n",
    "        output.write(str(row) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"peso_cero.txt\", 'w') as output:\n",
    "    for row in p_cero:\n",
    "        output.write(str(row) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
